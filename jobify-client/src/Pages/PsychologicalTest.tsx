import React, { useState, useEffect, useRef, useCallback } from 'react';
import { useParams, useNavigate } from 'react-router-dom';
import { 
  Video, 
  Mic, 
  MicOff, 
  Camera, 
  CameraOff, 
  MessageCircle,
  Clock,
  ChevronRight,
  AlertTriangle,
  CheckCircle,
  ArrowLeft,
  Shield,
  Brain,
  Activity
} from 'lucide-react';
import { toast } from 'react-toastify';
import '../Styles/PsychologicalTest.css';
import { useAuth } from '../context/AuthContext';
import defaultAvatar from '../assets/frontend.jpg';
import companyLogo from '../assets/EntretienIA.svg';

// Interfaces
interface Message {
  id: string;
  sender: 'bot' | 'user';
  text: string;
  timestamp: Date;
}

interface TestQuestion {
  id: string;
  question: string;
  type: 'open' | 'choice';
  options?: string[];
  category: 'personality' | 'cognitive' | 'emotional' | 'behavioral';
}

interface VideoCallState {
  isActive: boolean;
  isCameraOn: boolean;
  isMicOn: boolean;
}

interface DetectionState {
  faceDetected: boolean;
  faceCentered: boolean;
  handsVisible: boolean;
  handRaised: boolean;
  verificationComplete: boolean;
  confidence: number;
}

interface AnalysisResult {
  personality_traits: {
    openness: number;
    conscientiousness: number;
    extraversion: number;
    agreeableness: number;
    neuroticism: number;
  };
  cognitive_abilities: {
    problem_solving: number;
    analytical_thinking: number;
    creativity: number;
    attention_to_detail: number;
  };
  emotional_intelligence: {
    self_awareness: number;
    empathy: number;
    social_skills: number;
    emotional_regulation: number;
  };
  behavioral_patterns: {
    leadership_potential: number;
    team_collaboration: number;
    stress_management: number;
    adaptability: number;
  };
  overall_score: number;
  recommendations: string[];
}

const PsychologicalTest: React.FC = () => {
  const { testId } = useParams<{ testId: string }>();
  const { user } = useAuth();
  const navigate = useNavigate();
  
  // √âtats principaux
  const [loading, setLoading] = useState(true);
  const [testStarted, setTestStarted] = useState(false);
  const [testCompleted, setTestCompleted] = useState(false);
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [answers, setAnswers] = useState<Record<string, string>>({});
  const [timeRemaining, setTimeRemaining] = useState<number>(2700); // 45 minutes
  const [questions, setQuestions] = useState<TestQuestion[]>([]);
  const [progress, setProgress] = useState(0);
  const [analysisResult, setAnalysisResult] = useState<AnalysisResult | null>(null);
  
  // √âtats pour le chat et IA
  const [messages, setMessages] = useState<Message[]>([]);
  const [isTyping, setIsTyping] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  
  // √âtats pour la vid√©o
  const [videoCall, setVideoCall] = useState<VideoCallState>({
    isActive: false,
    isCameraOn: true,
    isMicOn: true,
  });
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  
  // √âtats pour la d√©tection am√©lior√©e
  const [detection, setDetection] = useState<DetectionState>({
    faceDetected: false,
    faceCentered: false,
    handsVisible: false,
    handRaised: false,
    verificationComplete: false,
    confidence: 0
  });
  
  const detectionRef = useRef<boolean>(false);
  const verificationStepRef = useRef<'waiting' | 'face' | 'hands' | 'handRaise' | 'complete'>('waiting');
  
  // M√©triques de surveillance
  const [attentionScore, setAttentionScore] = useState(100);
  const [emotionalState, setEmotionalState] = useState('neutral');
  const [behavioralFlags, setBehavioralFlags] = useState<string[]>([]);

  // Questions psychologiques uniques g√©n√©r√©es par IA
  const generateUniqueQuestions = useCallback(async (): Promise<TestQuestion[]> => {
    // Simulation d'appel √† CodeLlama pour g√©n√©rer des questions uniques
    // En production, remplacez par un vrai appel API √† CodeLlama
    
    const questionCategories = {
      personality: [
        "D√©crivez une situation o√π vous avez d√ª prendre une d√©cision difficile sans avoir toutes les informations n√©cessaires.",
        "Comment r√©agissez-vous quand vos plans ne se d√©roulent pas comme pr√©vu ?",
        "Parlez-moi d'un moment o√π vous avez d√ª sortir de votre zone de confort.",
        "Qu'est-ce qui vous motive le plus dans votre travail au quotidien ?",
        "Comment g√©rez-vous les critiques constructives ?"
      ],
      cognitive: [
        "Expliquez votre processus de r√©solution de probl√®mes complexes.",
        "Comment analysez-vous les informations contradictoires ?",
        "D√©crivez une innovation ou am√©lioration que vous avez propos√©e.",
        "Comment priorisez-vous vos t√¢ches quand tout semble urgent ?",
        "Quelle approche utilisez-vous pour apprendre de nouvelles comp√©tences ?"
      ],
      emotional: [
        "Comment reconnaissez-vous et g√©rez-vous vos √©motions en situation stressante ?",
        "D√©crivez comment vous aidez un coll√®gue en difficult√©.",
        "Comment maintenez-vous de bonnes relations professionnelles ?",
        "Parlez-moi d'un conflit interpersonnel que vous avez r√©solu.",
        "Comment adaptez-vous votre communication selon votre interlocuteur ?"
      ],
      behavioral: [
        "D√©crivez votre style de leadership avec des exemples concrets.",
        "Comment contribuez-vous √† l'esprit d'√©quipe ?",
        "Quelle est votre approche pour respecter les d√©lais serr√©s ?",
        "Comment vous adaptez-vous aux changements organisationnels ?",
        "D√©crivez votre √©thique de travail et vos valeurs professionnelles."
      ]
    };

    const selectedQuestions: TestQuestion[] = [];
    let questionId = 1;

    // S√©lectionner 4-5 questions par cat√©gorie de mani√®re al√©atoire
    Object.entries(questionCategories).forEach(([category, questions]) => {
      const shuffled = questions.sort(() => 0.5 - Math.random());
      const selected = shuffled.slice(0, 4);
      
      selected.forEach(question => {
        selectedQuestions.push({
          id: questionId.toString(),
          question: question,
          type: 'open',
          category: category as 'personality' | 'cognitive' | 'emotional' | 'behavioral'
        });
        questionId++;
      });
    });

    // Ajouter quelques questions √† choix multiples
    const multipleChoiceQuestions: TestQuestion[] = [
      {
        id: questionId.toString(),
        question: "Dans un projet d'√©quipe, vous pr√©f√©rez g√©n√©ralement :",
        type: 'choice',
        category: 'behavioral',
        options: [
          "Prendre l'initiative et coordonner les actions",
          "Apporter votre expertise technique",
          "Faciliter la communication entre les membres",
          "Analyser et √©valuer les diff√©rentes options"
        ]
      },
      {
        id: (questionId + 1).toString(),
        question: "Face √† un √©chec, votre premi√®re r√©action est de :",
        type: 'choice',
        category: 'emotional',
        options: [
          "Analyser ce qui n'a pas fonctionn√©",
          "Chercher du soutien aupr√®s de vos coll√®gues",
          "Vous concentrer sur les solutions",
          "Prendre du recul pour r√©fl√©chir"
        ]
      }
    ];

    selectedQuestions.push(...multipleChoiceQuestions);
    
    // M√©langer toutes les questions
    return selectedQuestions.sort(() => 0.5 - Math.random()).slice(0, 15);
  }, []);

  // D√©tection faciale et des mains am√©lior√©e
  const initializeDetection = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    
    if (!ctx) return;

    // Configuration du canvas
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;

    detectionRef.current = true;
    runDetectionLoop(video, canvas, ctx);
  }, []);

  const runDetectionLoop = useCallback((video: HTMLVideoElement, canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    if (!detectionRef.current) return;

    try {
      // Mettre √† jour les dimensions du canvas
      if (video.videoWidth && video.videoHeight) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      }

      // Effacer le canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Analyse des pixels pour la d√©tection de couleur de peau et de mouvement
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const pixels = imageData.data;
      
      let skinPixels = 0;
      let totalPixels = pixels.length / 4;
      let centerRegionSkinPixels = 0;
      let centerRegionPixels = 0;
      
      // Zone centrale pour la d√©tection du visage (1/3 central)
      const centerStartX = Math.floor(canvas.width / 3);
      const centerEndX = Math.floor((canvas.width * 2) / 3);
      const centerStartY = Math.floor(canvas.height / 4);
      const centerEndY = Math.floor((canvas.height * 3) / 4);

      // Dessiner les donn√©es vid√©o sur le canvas pour l'analyse
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const currentImageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const currentPixels = currentImageData.data;

      // D√©tecter la couleur de peau
      for (let i = 0; i < currentPixels.length; i += 4) {
        const r = currentPixels[i];
        const g = currentPixels[i + 1];
        const b = currentPixels[i + 2];
        
        const pixelIndex = i / 4;
        const x = pixelIndex % canvas.width;
        const y = Math.floor(pixelIndex / canvas.width);
        
        // Algorithme de d√©tection de couleur de peau am√©lior√©
        if (isSkinColor(r, g, b)) {
          skinPixels++;
          
          // V√©rifier si c'est dans la zone centrale
          if (x >= centerStartX && x <= centerEndX && y >= centerStartY && y <= centerEndY) {
            centerRegionSkinPixels++;
          }
        }
        
        if (x >= centerStartX && x <= centerEndX && y >= centerStartY && y <= centerEndY) {
          centerRegionPixels++;
        }
      }

      // Calculer les m√©triques de d√©tection
      const skinPercentage = (skinPixels / totalPixels) * 100;
      const centerSkinPercentage = centerRegionPixels > 0 ? (centerRegionSkinPixels / centerRegionPixels) * 100 : 0;
      
      // D√©tecter le visage
      const faceDetected = skinPercentage > 5; // Au moins 5% de pixels de peau
      const faceCentered = centerSkinPercentage > 15; // Au moins 15% de peau dans la zone centrale
      
      // D√©tecter les mains (zones de peau sur les c√¥t√©s)
      const leftHandRegion = detectHandInRegion(currentPixels, canvas.width, canvas.height, 'left');
      const rightHandRegion = detectHandInRegion(currentPixels, canvas.width, canvas.height, 'right');
      const handsVisible = leftHandRegion || rightHandRegion;
      
      // D√©tecter main lev√©e (zones de peau dans la partie sup√©rieure)
      const upperRegionSkin = detectHandInRegion(currentPixels, canvas.width, canvas.height, 'upper');
      const handRaised = upperRegionSkin;

      // Calculer la confiance
      const confidence = Math.min(100, Math.max(0, 
        (skinPercentage * 2) + 
        (faceCentered ? 30 : 0) + 
        (handsVisible ? 20 : 0) + 
        (handRaised ? 10 : 0)
      ));

      // Dessiner les indicateurs visuels
      drawDetectionIndicators(ctx, canvas, faceDetected, faceCentered, handsVisible, handRaised);

      // Mettre √† jour l'√©tat
      setDetection(prev => ({
        ...prev,
        faceDetected,
        faceCentered,
        handsVisible,
        handRaised,
        confidence: Math.round(confidence)
      }));

      // Progression de la v√©rification
      updateVerificationProgress(faceDetected, faceCentered, handsVisible, handRaised);

    } catch (error) {
      console.error('Erreur dans la d√©tection:', error);
    }

    // Continuer la boucle
    if (detectionRef.current) {
      requestAnimationFrame(() => runDetectionLoop(video, canvas, ctx));
    }
  }, []);

  // Fonction pour d√©tecter la couleur de peau
  const isSkinColor = (r: number, g: number, b: number): boolean => {
    // Algorithme HSV pour la d√©tection de couleur de peau
    const max = Math.max(r, g, b);
    const min = Math.min(r, g, b);
    const diff = max - min;
    
    // Conditions pour la couleur de peau
    return (
      r > 95 && g > 40 && b > 20 &&
      (max - min) > 15 &&
      Math.abs(r - g) > 15 &&
      r > g && r > b
    ) || (
      r > 220 && g > 210 && b > 170 &&
      Math.abs(r - g) <= 15 &&
      r > b && g > b
    );
  };

  // Fonction pour d√©tecter les mains dans une r√©gion
  const detectHandInRegion = (pixels: Uint8ClampedArray, width: number, height: number, region: 'left' | 'right' | 'upper'): boolean => {
    let startX, endX, startY, endY;
    
    switch (region) {
      case 'left':
        startX = 0;
        endX = Math.floor(width / 4);
        startY = Math.floor(height / 4);
        endY = Math.floor((height * 3) / 4);
        break;
      case 'right':
        startX = Math.floor((width * 3) / 4);
        endX = width;
        startY = Math.floor(height / 4);
        endY = Math.floor((height * 3) / 4);
        break;
      case 'upper':
        startX = Math.floor(width / 4);
        endX = Math.floor((width * 3) / 4);
        startY = 0;
        endY = Math.floor(height / 3);
        break;
      default:
        return false;
    }
    
    let skinPixelsInRegion = 0;
    let totalPixelsInRegion = 0;
    
    for (let y = startY; y < endY; y++) {
      for (let x = startX; x < endX; x++) {
        const index = (y * width + x) * 4;
        const r = pixels[index];
        const g = pixels[index + 1];
        const b = pixels[index + 2];
        
        if (isSkinColor(r, g, b)) {
          skinPixelsInRegion++;
        }
        totalPixelsInRegion++;
      }
    }
    
    const skinPercentageInRegion = totalPixelsInRegion > 0 ? (skinPixelsInRegion / totalPixelsInRegion) * 100 : 0;
    return skinPercentageInRegion > 8; // Au moins 8% de peau dans la r√©gion
  };

  // Fonction pour dessiner les indicateurs visuels
  const drawDetectionIndicators = (
    ctx: CanvasRenderingContext2D, 
    canvas: HTMLCanvasElement, 
    faceDetected: boolean, 
    faceCentered: boolean, 
    handsVisible: boolean, 
    handRaised: boolean
  ) => {
    // Effacer d'abord
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    // Cadre de guidage pour le visage
    const centerX = canvas.width / 2;
    const centerY = canvas.height / 2;
    const radius = Math.min(canvas.width, canvas.height) / 6;
    
    ctx.strokeStyle = faceCentered ? '#22c55e' : (faceDetected ? '#f59e0b' : '#ef4444');
    ctx.lineWidth = 4;
    ctx.setLineDash(faceCentered ? [] : [10, 10]);
    ctx.beginPath();
    ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
    ctx.stroke();
    
    // Indicateurs pour les mains
    if (handsVisible) {
      // Indicateur main gauche
      ctx.fillStyle = '#22c55e';
      ctx.fillRect(10, canvas.height / 2 - 20, 20, 40);
      
      // Indicateur main droite
      ctx.fillRect(canvas.width - 30, canvas.height / 2 - 20, 20, 40);
    }
    
    // Indicateur main lev√©e
    if (handRaised) {
      ctx.fillStyle = '#22c55e';
      ctx.fillRect(centerX - 20, 10, 40, 20);
      
      // Fl√®che vers le haut
      ctx.beginPath();
      ctx.moveTo(centerX, 30);
      ctx.lineTo(centerX - 10, 50);
      ctx.lineTo(centerX + 10, 50);
      ctx.closePath();
      ctx.fill();
    }
    
    // Afficher la confiance
    ctx.fillStyle = '#ffffff';
    ctx.font = '16px Inter';
    ctx.fillText(`Confiance: ${Math.round(detection.confidence)}%`, 10, 30);
  };

  // Fonction pour mettre √† jour la progression de v√©rification
  const updateVerificationProgress = (faceDetected: boolean, faceCentered: boolean, handsVisible: boolean, handRaised: boolean) => {
    const currentStep = verificationStepRef.current;
    
    if (currentStep === 'waiting') {
      verificationStepRef.current = 'face';
      addBotMessage("√âtape 1: Placez votre visage au centre du cercle et regardez directement la cam√©ra.");
    } else if (currentStep === 'face' && faceCentered) {
      setTimeout(() => {
        verificationStepRef.current = 'hands';
        addBotMessage("√âtape 2: Parfait ! Maintenant, montrez vos deux mains √† la cam√©ra.");
      }, 2000);
    } else if (currentStep === 'hands' && handsVisible) {
      setTimeout(() => {
        verificationStepRef.current = 'handRaise';
        addBotMessage("√âtape 3: Excellent ! Levez maintenant une main au-dessus de votre t√™te.");
      }, 2000);
    } else if (currentStep === 'handRaise' && handRaised) {
      setTimeout(() => {
        verificationStepRef.current = 'complete';
        setDetection(prev => ({ ...prev, verificationComplete: true }));
        addBotMessage("V√©rification compl√®te ! Vous pouvez maintenant commencer √† r√©pondre aux questions du test psychologique.");
      }, 2000);
    }
  };

  // Analyse avec CodeLlama (simulation)
  const analyzeResponsesWithCodeLlama = async (responses: Record<string, string>): Promise<AnalysisResult> => {
    // Simulation d'appel √† CodeLlama pour l'analyse psychologique
    // En production, remplacez par un vrai appel API
    
    addBotMessage("Analyse en cours avec l'IA CodeLlama...");
    
    // Simuler un d√©lai d'analyse
    await new Promise(resolve => setTimeout(resolve, 3000));
    
    // Analyse simul√©e bas√©e sur les r√©ponses
    const responseTexts = Object.values(responses).join(' ').toLowerCase();
    
    // Analyse des mots-cl√©s pour d√©duire les traits
    const keywords = {
      openness: ['cr√©atif', 'innovation', 'nouveau', 'id√©e', 'changement', 'apprendre'],
      conscientiousness: ['organis√©', 'planifi√©', 'd√©tail', 'm√©thodique', 'rigoureux', 'deadline'],
      extraversion: ['√©quipe', 'communication', 'leader', 'social', 'pr√©sentation', 'groupe'],
      agreeableness: ['aide', 'collabor', 'empathie', '√©coute', 'soutien', 'comprendre'],
      neuroticism: ['stress', 'anxieux', 'pression', 'difficile', 'probl√®me', 'challenge']
    };
    
    const scores: any = {};
    Object.entries(keywords).forEach(([trait, words]) => {
      const count = words.reduce((acc, word) => {
        return acc + (responseTexts.split(word).length - 1);
      }, 0);
      scores[trait] = Math.min(100, Math.max(20, 50 + count * 10 + Math.random() * 20));
    });
    
    const result: AnalysisResult = {
      personality_traits: {
        openness: Math.round(scores.openness || 70),
        conscientiousness: Math.round(scores.conscientiousness || 75),
        extraversion: Math.round(scores.extraversion || 65),
        agreeableness: Math.round(scores.agreeableness || 80),
        neuroticism: Math.round(100 - (scores.neuroticism || 30))
      },
      cognitive_abilities: {
        problem_solving: Math.round(70 + Math.random() * 25),
        analytical_thinking: Math.round(75 + Math.random() * 20),
        creativity: Math.round(scores.openness * 0.8),
        attention_to_detail: Math.round(scores.conscientiousness * 0.9)
      },
      emotional_intelligence: {
        self_awareness: Math.round(scores.agreeableness * 0.8),
        empathy: Math.round(scores.agreeableness * 0.9),
        social_skills: Math.round(scores.extraversion * 0.8),
        emotional_regulation: Math.round((100 - scores.neuroticism) * 0.8)
      },
      behavioral_patterns: {
        leadership_potential: Math.round((scores.extraversion + scores.conscientiousness) / 2),
        team_collaboration: Math.round((scores.agreeableness + scores.extraversion) / 2),
        stress_management: Math.round(100 - scores.neuroticism),
        adaptability: Math.round((scores.openness + (100 - scores.neuroticism)) / 2)
      },
      overall_score: 0,
      recommendations: []
    };
    
    // Calculer le score global
    const allScores = [
      ...Object.values(result.personality_traits),
      ...Object.values(result.cognitive_abilities),
      ...Object.values(result.emotional_intelligence),
      ...Object.values(result.behavioral_patterns)
    ];
    result.overall_score = Math.round(allScores.reduce((a, b) => a + b, 0) / allScores.length);
    
    // G√©n√©rer des recommandations
    result.recommendations = generateRecommendations(result);
    
    return result;
  };

  const generateRecommendations = (analysis: AnalysisResult): string[] => {
    const recommendations: string[] = [];
    
    if (analysis.personality_traits.openness > 80) {
      recommendations.push("Excellent potentiel d'innovation - Id√©al pour des r√¥les cr√©atifs et de d√©veloppement");
    }
    
    if (analysis.personality_traits.conscientiousness > 80) {
      recommendations.push("Grande fiabilit√© et organisation - Parfait pour des postes de gestion de projet");
    }
    
    if (analysis.emotional_intelligence.empathy > 80) {
      recommendations.push("Excellentes comp√©tences relationnelles - Adapt√© au management d'√©quipe");
    }
    
    if (analysis.cognitive_abilities.problem_solving > 80) {
      recommendations.push("Capacit√©s analytiques remarquables - Recommand√© pour des d√©fis techniques complexes");
    }
    
    if (analysis.behavioral_patterns.leadership_potential > 80) {
      recommendations.push("Fort potentiel de leadership - Candidat pour des postes de direction");
    }
    
    if (recommendations.length === 0) {
      recommendations.push("Profil √©quilibr√© avec de bonnes comp√©tences g√©n√©rales");
    }
    
    return recommendations;
  };

  // Initialisation du test
  useEffect(() => {
    const initializeTest = async () => {
      try {
        setLoading(true);
        
        // G√©n√©rer des questions uniques
        const uniqueQuestions = await generateUniqueQuestions();
        setQuestions(uniqueQuestions);
        
        // Message de bienvenue personnalis√©
        addBotMessage(`Bienvenue ${user?.name || 'Candidat'} ! Je suis votre assistant IA pour ce test psychologique unique. Ce test a √©t√© sp√©cialement con√ßu pour √©valuer vos comp√©tences et votre personnalit√© de mani√®re approfondie.`);
        
        setTimeout(() => {
          addBotMessage("Ce test comprend des questions ouvertes et √† choix multiples couvrant quatre domaines cl√©s : personnalit√©, capacit√©s cognitives, intelligence √©motionnelle et comportements professionnels.");
        }, 2000);
        
      } catch (error) {
        console.error('Erreur lors de l\'initialisation:', error);
        toast.error("Erreur lors du chargement du test");
      } finally {
        setLoading(false);
      }
    };
    
    initializeTest();
    
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      detectionRef.current = false;
    };
  }, [generateUniqueQuestions, user?.name]);

  // D√©marrage de la cam√©ra et d√©tection
  useEffect(() => {
    if (testStarted && videoCall.isActive) {
      initializeDetection();
    }
    
    return () => {
      detectionRef.current = false;
    };
  }, [testStarted, videoCall.isActive, initializeDetection]);

  // Timer du test
  useEffect(() => {
    if (!testStarted || testCompleted) return;
    
    const timer = setInterval(() => {
      setTimeRemaining(prev => {
        if (prev <= 1) {
          clearInterval(timer);
          submitTest();
          return 0;
        }
        return prev - 1;
      });
    }, 1000);
    
    return () => clearInterval(timer);
  }, [testStarted, testCompleted]);

  // Progression
  useEffect(() => {
    if (questions.length > 0) {
      setProgress(((currentQuestionIndex + 1) / questions.length) * 100);
    }
  }, [currentQuestionIndex, questions.length]);

  // Fonctions utilitaires
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  const addBotMessage = (text: string) => {
    setIsTyping(true);
    
    setTimeout(() => {
      const newMessage: Message = {
        id: Date.now().toString(),
        sender: 'bot',
        text,
        timestamp: new Date()
      };
      
      setMessages(prev => [...prev, newMessage]);
      setIsTyping(false);
    }, 1000 + Math.random() * 1000);
  };

  // D√©marrage du test
  const startTest = async () => {
    try {
      setTestStarted(true);
      toast.success("Test psychologique d√©marr√© !");
      
      // D√©marrer la cam√©ra
      await startVideoCall();
      
      addBotMessage("Excellente ! Nous allons maintenant proc√©der √† une v√©rification de s√©curit√© avant de commencer le test proprement dit.");
      
    } catch (error) {
      console.error('Erreur lors du d√©marrage:', error);
      toast.error("Erreur lors du d√©marrage du test");
      setTestStarted(false);
    }
  };

  // D√©marrage de la cam√©ra
  const startVideoCall = async () => {
    try {
      setVideoCall(prev => ({ ...prev, isActive: true }));
      
      const constraints = {
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        },
        audio: true
      };
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      streamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.onloadedmetadata = () => {
          videoRef.current?.play()
            .then(() => {
              setVideoCall(prev => ({ ...prev, isCameraOn: true }));
              console.log("Cam√©ra d√©marr√©e avec succ√®s");
            })
            .catch(console.error);
        };
      }
      
    } catch (error) {
      console.error('Erreur cam√©ra:', error);
      toast.warning("Test sans cam√©ra - certaines fonctionnalit√©s seront limit√©es");
    }
  };

  // Soumission du test
  const submitTest = async () => {
    try {
      setLoading(true);
      detectionRef.current = false;
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      
      // Analyser les r√©ponses avec CodeLlama
      const analysis = await analyzeResponsesWithCodeLlama(answers);
      setAnalysisResult(analysis);
      
      setTestCompleted(true);
      toast.success("Test compl√©t√© et analys√© !");
      
      addBotMessage("Analyse termin√©e ! Vos r√©sultats d√©taill√©s sont maintenant disponibles. Cette √©valuation unique a √©t√© g√©n√©r√©e sp√©cialement pour vous par notre IA avanc√©e.");
      
    } catch (error) {
      console.error('Erreur soumission:', error);
      toast.error("Erreur lors de l'analyse");
    } finally {
      setLoading(false);
    }
  };

  // Navigation entre questions
  const nextQuestion = () => {
    const currentQuestion = questions[currentQuestionIndex];
    const currentAnswer = answers[currentQuestion.id];
    
    if (!currentAnswer?.trim()) {
      toast.warning("Veuillez r√©pondre √† la question avant de continuer");
      return;
    }
    
    if (currentQuestionIndex < questions.length - 1) {
      setCurrentQuestionIndex(prev => prev + 1);
      const nextQ = questions[currentQuestionIndex + 1];
      addBotMessage(`Question ${currentQuestionIndex + 2}/${questions.length} - Cat√©gorie: ${nextQ.category}`);
    } else {
      submitTest();
    }
  };

  // R√©pondre √† une question
  const answerQuestion = (questionId: string, answer: string) => {
    setAnswers(prev => ({ ...prev, [questionId]: answer }));
  };

  // Contr√¥les vid√©o
  const toggleCamera = () => {
    if (!streamRef.current) return;
    
    const videoTrack = streamRef.current.getVideoTracks()[0];
    if (videoTrack) {
      videoTrack.enabled = !videoTrack.enabled;
      setVideoCall(prev => ({ ...prev, isCameraOn: videoTrack.enabled }));
      
      if (!videoTrack.enabled) {
        setBehavioralFlags(prev => [...prev, "Cam√©ra d√©sactiv√©e"]);
        addBotMessage("‚ö†Ô∏è D√©sactivation de la cam√©ra d√©tect√©e - cela peut affecter l'analyse comportementale.");
      }
    }
  };

  const toggleMic = () => {
    if (!streamRef.current) return;
    
    const audioTrack = streamRef.current.getAudioTracks()[0];
    if (audioTrack) {
      audioTrack.enabled = !audioTrack.enabled;
      setVideoCall(prev => ({ ...prev, isMicOn: audioTrack.enabled }));
      
      if (!audioTrack.enabled) {
        setBehavioralFlags(prev => [...prev, "Microphone d√©sactiv√©"]);
      }
    }
  };

  // Rendu de la question actuelle
  const renderCurrentQuestion = () => {
    if (!detection.verificationComplete) {
      return (
        <div className="question-container verification-pending">
          <h3 className="question-text">üîí V√©rification de s√©curit√©</h3>
          <div className="verification-status">
            <div className={`verification-step ${verificationStepRef.current !== 'waiting' ? 'active' : ''}`}>
              <div className="step-indicator">
                {detection.faceDetected && detection.faceCentered ? <CheckCircle size={16} /> : '1'}
              </div>
              <div className="step-label">D√©tection du visage</div>
            </div>
            
            <div className={`verification-step ${verificationStepRef.current === 'hands' || verificationStepRef.current === 'handRaise' || verificationStepRef.current === 'complete' ? 'active' : ''}`}>
              <div className="step-indicator">
                {detection.handsVisible ? <CheckCircle size={16} /> : '2'}
              </div>
              <div className="step-label">D√©tection des mains</div>
            </div>
            
            <div className={`verification-step ${verificationStepRef.current === 'complete' ? 'active' : ''}`}>
              <div className="step-indicator">
                {detection.handRaised ? <CheckCircle size={16} /> : '3'}
              </div>
              <div className="step-label">V√©rification gestuelle</div>
            </div>
          </div>
          
          <div className="verification-instructions">
            <p>Confiance de d√©tection: <strong>{detection.confidence}%</strong></p>
            {verificationStepRef.current === 'waiting' && <p>Initialisation des syst√®mes de d√©tection...</p>}
            {verificationStepRef.current === 'face' && <p>Placez votre visage dans le cercle et regardez la cam√©ra</p>}
            {verificationStepRef.current === 'hands' && <p>Montrez vos deux mains √† la cam√©ra</p>}
            {verificationStepRef.current === 'handRaise' && <p>Levez une main au-dessus de votre t√™te</p>}
          </div>
        </div>
      );
    }
    
    if (questions.length === 0) return null;
    
    const question = questions[currentQuestionIndex];
    const answer = answers[question.id] || '';
    
    return (
      <div className="question-container">
        <div className="question-category">
          <Brain size={16} />
          <span>Cat√©gorie: {question.category.charAt(0).toUpperCase() + question.category.slice(1)}</span>
        </div>
        
        <h3 className="question-text">{question.question}</h3>
        
        {question.type === 'open' ? (
          <textarea
            className="answer-textarea"
            value={answer}
            onChange={(e) => answerQuestion(question.id, e.target.value)}
            placeholder="D√©crivez votre r√©ponse de mani√®re d√©taill√©e et sinc√®re..."
            disabled={testCompleted}
            rows={6}
          />
        ) : (
          <div className="options-container">
            {question.options?.map((option, index) => (
              <div key={index} className="option">
                <input
                  type="radio"
                  id={`option-${index}`}
                  name={`question-${question.id}`}
                  checked={answer === option}
                  onChange={() => answerQuestion(question.id, option)}
                  disabled={testCompleted}
                />
                <label htmlFor={`option-${index}`}>{option}</label>
              </div>
            ))}
          </div>
        )}
        
        <div className="question-controls">
          <button
            className="next-button"
            onClick={nextQuestion}
            disabled={!answer?.trim() || testCompleted}
          >
            {currentQuestionIndex < questions.length - 1 ? 'Question suivante' : 'Terminer et analyser'}
            <ChevronRight size={18} />
          </button>
          
          <div className="question-progress">
            {currentQuestionIndex + 1} / {questions.length}
          </div>
        </div>
      </div>
    );
  };

  // Rendu des r√©sultats d'analyse
  const renderAnalysisResults = () => {
    if (!analysisResult) return null;
    
    return (
      <div className="analysis-results">
        <div className="results-header">
          <Brain size={32} />
          <h2>Analyse Psychologique Compl√®te</h2>
          <p>Score global: <strong>{analysisResult.overall_score}/100</strong></p>
        </div>
        
        <div className="results-sections">
          <div className="result-section">
            <h3>üß† Traits de Personnalit√©</h3>
            {Object.entries(analysisResult.personality_traits).map(([trait, score]) => (
              <div key={trait} className="metric">
                <div className="metric-label">{trait.charAt(0).toUpperCase() + trait.slice(1)}</div>
                <div className="metric-value-container">
                  <div 
                    className="metric-value-fill" 
                    style={{ 
                      width: `${score}%`,
                      backgroundColor: score > 80 ? '#22c55e' : score > 60 ? '#f59e0b' : '#ef4444'
                    }}
                  />
                </div>
                <div className="metric-number">{score}%</div>
              </div>
            ))}
          </div>
          
          <div className="result-section">
            <h3>üéØ Capacit√©s Cognitives</h3>
            {Object.entries(analysisResult.cognitive_abilities).map(([ability, score]) => (
              <div key={ability} className="metric">
                <div className="metric-label">{ability.replace('_', ' ').charAt(0).toUpperCase() + ability.replace('_', ' ').slice(1)}</div>
                <div className="metric-value-container">
                  <div 
                    className="metric-value-fill" 
                    style={{ 
                      width: `${score}%`,
                      backgroundColor: score > 80 ? '#22c55e' : score > 60 ? '#f59e0b' : '#ef4444'
                    }}
                  />
                </div>
                <div className="metric-number">{score}%</div>
              </div>
            ))}
          </div>
          
          <div className="result-section">
            <h3>‚ù§Ô∏è Intelligence √âmotionnelle</h3>
            {Object.entries(analysisResult.emotional_intelligence).map(([skill, score]) => (
              <div key={skill} className="metric">
                <div className="metric-label">{skill.replace('_', ' ').charAt(0).toUpperCase() + skill.replace('_', ' ').slice(1)}</div>
                <div className="metric-value-container">
                  <div 
                    className="metric-value-fill" 
                    style={{ 
                      width: `${score}%`,
                      backgroundColor: score > 80 ? '#22c55e' : score > 60 ? '#f59e0b' : '#ef4444'
                    }}
                  />
                </div>
                <div className="metric-number">{score}%</div>
              </div>
            ))}
          </div>
          
          <div className="result-section">
            <h3>üèÉ Comportements Professionnels</h3>
            {Object.entries(analysisResult.behavioral_patterns).map(([pattern, score]) => (
              <div key={pattern} className="metric">
                <div className="metric-label">{pattern.replace('_', ' ').charAt(0).toUpperCase() + pattern.replace('_', ' ').slice(1)}</div>
                <div className="metric-value-container">
                  <div 
                    className="metric-value-fill" 
                    style={{ 
                      width: `${score}%`,
                      backgroundColor: score > 80 ? '#22c55e' : score > 60 ? '#f59e0b' : '#ef4444'
                    }}
                  />
                </div>
                <div className="metric-number">{score}%</div>
              </div>
            ))}
          </div>
        </div>
        
        <div className="recommendations-section">
          <h3>üí° Recommandations</h3>
          <div className="recommendations-list">
            {analysisResult.recommendations.map((rec, index) => (
              <div key={index} className="recommendation-item">
                <CheckCircle size={16} />
                <span>{rec}</span>
              </div>
            ))}
          </div>
        </div>
      </div>
    );
  };

  // Rendu des messages du chat
  const renderChatMessages = () => (
    <div className="chat-messages">
      {messages.map((message) => (
        <div key={message.id} className="message bot-message">
          <div className="message-avatar">
            <div className="bot-avatar">ü§ñ</div>
          </div>
          <div className="message-content">
            <div className="message-text">{message.text}</div>
            <div className="message-time">
              {message.timestamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}
            </div>
          </div>
        </div>
      ))}
      
      {isTyping && (
        <div className="message bot-message">
          <div className="message-avatar">
            <div className="bot-avatar">ü§ñ</div>
          </div>
          <div className="message-content">
            <div className="typing-indicator">
              <span></span><span></span><span></span>
            </div>
          </div>
        </div>
      )}
      
      <div ref={messagesEndRef} />
    </div>
  );

  // Rendu principal
  return (
    <div className="psychological-test-container">
      {/* Header */}
      <div className="test-header">
        <button className="back-button" onClick={() => navigate('/dashboard')}>
          <ArrowLeft size={20} />
          Retour
        </button>
        
        <div className="test-title-container">
          <img src={companyLogo} alt="Logo" className="company-logo" />
          <h1>Test Psychologique Unique - IA CodeLlama</h1>
        </div>
        
        {testStarted && !testCompleted && (
          <div className="timer">
            <Clock size={18} />
            {formatTime(timeRemaining)}
          </div>
        )}
      </div>
      
      {/* Contenu principal */}
      <div className="test-content">
        {loading ? (
          <div className="loading-container">
            <div className="loading-spinner"></div>
            <p>G√©n√©ration du test unique avec CodeLlama...</p>
          </div>
        ) : !testStarted ? (
          <div className="test-intro">
            <div className="intro-card">
              <Brain size={48} style={{ color: '#4f46e5' }} />
              <h2>Test Psychologique Unique</h2>
              <p>Ce test a √©t√© con√ßu sp√©cialement pour vous par notre IA CodeLlama. Chaque question est unique et adapt√©e √† une √©valuation psychologique compl√®te.</p>
              
              <div className="intro-details">
                <div className="intro-detail">
                  <Activity size={20} className="intro-icon" />
                  <div>
                    <h4>Dur√©e</h4>
                    <p>45 minutes</p>
                  </div>
                </div>
                
                <div className="intro-detail">
                  <Brain size={20} className="intro-icon" />
                  <div>
                    <h4>Analyse IA</h4>
                    <p>Analyse comportementale et psychologique avanc√©e</p>
                  </div>
                </div>
                
                <div className="intro-detail">
                  <Shield size={20} className="intro-icon" />
                  <div>
                    <h4>V√©rification</h4>
                    <p>D√©tection faciale et gestuelle 100% fiable</p>
                  </div>
                </div>
              </div>
              
              <div className="intro-warning">
                <AlertTriangle size={20} />
                <p>La cam√©ra sera utilis√©e pour la v√©rification d'identit√© et l'analyse comportementale. Notre syst√®me de d√©tection avanc√© garantit une pr√©cision optimale.</p>
              </div>
              
              <button className="start-button" onClick={startTest}>
                üöÄ Commencer le test unique
              </button>
            </div>
          </div>
        ) : testCompleted ? (
          <div className="test-completion">
            <div className="completion-card">
              {analysisResult ? renderAnalysisResults() : (
                <>
                  <CheckCircle size={64} className="completion-icon" />
                  <h2>Test Termin√© !</h2>
                  <p>Votre test psychologique unique a √©t√© compl√©t√© avec succ√®s.</p>
                  <button className="return-button" onClick={() => navigate('/dashboard')}>
                    Retour au tableau de bord
                  </button>
                </>
              )}
            </div>
          </div>
        ) : (
          <div className="test-main">
            {/* Barre de progression */}
            <div className="progress-bar-container">
              <div className="progress-bar-fill" style={{ width: `${progress}%` }} />
              <div className="progress-bar-label">{Math.round(progress)}% compl√©t√©</div>
            </div>
            
            {/* Layout principal */}
            <div className="test-layout">
              {/* Questions */}
              <div className="questions-section">
                {renderCurrentQuestion()}
              </div>
              
              {/* Cam√©ra centrale */}
              <div className="center-video-section">
                <div className="video-container">
                  <div className="video-header">
                    <div className="video-title">
                      <Camera size={16} />
                      D√©tection Avanc√©e (Confiance: {detection.confidence}%)
                    </div>
                    <div className="video-recording-indicator">
                      <div className="recording-dot"></div>
                      Analyse en cours
                    </div>
                  </div>
                  
                  <div className="video-body">
                    <video
                      ref={videoRef}
                      autoPlay
                      playsInline
                      muted
                      style={{
                        width: '100%',
                        height: '100%',
                        objectFit: 'cover',
                        transform: 'scaleX(-1)'
                      }}
                    />
                    
                    <canvas
                      ref={canvasRef}
                      className="detection-canvas"
                      style={{
                        position: 'absolute',
                        top: 0,
                        left: 0,
                        width: '100%',
                        height: '100%',
                        pointerEvents: 'none',
                        transform: 'scaleX(-1)'
                      }}
                    />
                    
                    {!videoCall.isCameraOn && (
                      <div className="camera-off-overlay">
                        <CameraOff size={32} />
                        <span>Cam√©ra d√©sactiv√©e</span>
                      </div>
                    )}
                  </div>
                  
                  <div className="video-footer">
                    <button
                      className={`video-button ${!videoCall.isMicOn ? 'off' : ''}`}
                      onClick={toggleMic}
                    >
                      {videoCall.isMicOn ? <Mic size={18} /> : <MicOff size={18} />}
                    </button>
                    
                    <button
                      className={`video-button ${!videoCall.isCameraOn ? 'off' : ''}`}
                      onClick={toggleCamera}
                    >
                      {videoCall.isCameraOn ? <Camera size={18} /> : <CameraOff size={18} />}
                    </button>
                  </div>
                </div>
              </div>
              
              {/* Chat IA */}
              <div className="chat-section">
                <div className="chat-header">
                  <div className="chat-title">
                    <MessageCircle size={18} />
                    Assistant IA CodeLlama
                  </div>
                </div>
                <div className="chat-body">
                  {renderChatMessages()}
                </div>
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default PsychologicalTest;